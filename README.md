#ğŸ¤– AI-Based Hand Gesture Recognition for Text-to-Speech Communication

ğŸ“Œ Overview

This project develops an AI-driven system that translates hand gestures into spoken words using Machine Learning, OpenCV, and Text-to-Speech (TTS) technology.

The goal is to improve accessibility for individuals with hearing and speech impairments by enabling communication with non-sign-language users in real time.

Programme: PRJ381 â€“ Project 381
Module Level: NQF 8 (BCom â€“ Data Science/IT)
Academic Year: 2025

#ğŸ¯ Objectives

ğŸš€ Develop a real-time hand gesture recognition system.

ğŸ”Š Integrate Text-to-Speech (TTS) for gesture-to-speech conversion.

ğŸ§  Apply deep learning techniques to improve classification accuracy.

ğŸ‘¥ Test the application with real users for usability and effectiveness.

#ğŸ› ï¸ Features

âœ… Real-time hand gesture detection (via OpenCV + MediaPipe)

âœ… Gesture classification using CNN / transfer learning (TensorFlow / PyTorch)

âœ… Text-to-Speech integration (gTTS, pyttsx3)

âœ… Python-based application with GUI interface (Tkinter / Flask)

âœ… Works across different skin tones, hand sizes, and lighting conditions

#ğŸ“‚ Repository Structure
PRJ381-Sim/
â”‚â”€â”€ data/                # Gesture datasets (raw & preprocessed)
â”‚â”€â”€ models/              # Trained CNN / transfer learning models
â”‚â”€â”€ notebooks/           # Jupyter/Colab notebooks for training & testing
â”‚â”€â”€ src/                 # Source code (Python scripts)
â”‚   â”œâ”€â”€ hand_tracking.py
â”‚   â”œâ”€â”€ gesture_classification.py
â”‚   â”œâ”€â”€ tts_integration.py
â”‚   â””â”€â”€ app.py           # Main application (GUI + real-time recognition)
â”‚â”€â”€ docs/                # Documentation, study guide & reports
â”‚â”€â”€ results/             # Test results, accuracy metrics, confusion matrices
â”‚â”€â”€ README.md            # Project overview (this file)
â”‚â”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ LICENSE              # License file

#âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/<your-username>/PRJ381-Hand-Gesture-Recognition.git
cd PRJ381-Hand-Gesture-Recognition

2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the application
python src/app.py

#ğŸ“Š Methodology

ğŸ“· Data Collection â€“ Capture gesture dataset with OpenCV + MediaPipe, label gestures (e.g., Hello, Thank You, Help).

ğŸ§‘â€ğŸ’» Model Training â€“ Train CNN / transfer learning models in TensorFlow/Keras or PyTorch. Evaluate accuracy, precision, recall, and F1-score.

âœ‹ Real-Time Recognition â€“ Implement gesture detection with OpenCV + MediaPipe Hands.

ğŸ”Š Gesture-to-Speech Conversion â€“ Convert gestures â†’ text â†’ speech via gTTS / pyttsx3.

ğŸ§ª Testing & Evaluation â€“ Conduct usability tests with speech-impaired users. Optimize for lighting, hand sizes, and skin tones.

ğŸ“ˆ Project Timeline (Milestones)

ğŸ“… Milestone 1 (Aprâ€“May 2025): Project Planning & Design

âš™ï¸ Milestone 2 (Julâ€“Oct 2025): Implementation & Testing

ğŸ¤ Expo Presentation (Oct 2025): Final demo & evaluation

ğŸ“ Final Report (Oct 2025): Submission of academic report

#ğŸ”§ Tools & Technologies

ğŸ Python (OpenCV, TensorFlow, PyTorch, MediaPipe)

ğŸ”Š gTTS / pyttsx3 (Text-to-Speech)

ğŸ–¥ï¸ Tkinter / Flask (GUI development)

ğŸ““ Jupyter Notebook / Google Colab (Model training & experiments)

ğŸ‘¥ Team & Collaboration

ğŸ§‘â€ğŸ« Supervisors: TBA

ğŸ‘©â€ğŸ’» Team Members: PRJ381 Student Group (2025)

ğŸ’¬ Collaboration via MS Teams, Moodle, Email

ğŸŒ Potential Partners

DEAFinition NPC

SANDA â€“ South African National Deaf Association

#ğŸ“š References

Google translates gestures to speech

TechVidvan â€“ Hand Gesture Recognition

UCT Gesture Recognition Project

IJCAI 2023 Research Paper

#ğŸ“œ License

This project is developed for academic purposes (PRJ381, 2025).
Usage beyond research and education requires permission.

âœ¨ This repository forms part of the PRJ381 capstone project at Belgium Campus iTversity, focusing on accessibility through AI-driven hand gesture recognition.
