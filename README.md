# ğŸ¤– AI-Based Hand Gesture Recognition for Text-to-Speech Communication  

![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)  
![OpenCV](https://img.shields.io/badge/OpenCV-4.9-green.svg)  
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.16-orange.svg)  
![PyTorch](https://img.shields.io/badge/PyTorch-2.2-red.svg)  
![License](https://img.shields.io/badge/license-Academic-lightgrey.svg)  
![Contributions](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)  

---

## ğŸ“Œ Overview  

This project develops an **AI-driven system that translates hand gestures into spoken words** using **Machine Learning, OpenCV, and Text-to-Speech (TTS) technology**.  

The goal is to improve accessibility for **individuals with hearing and speech impairments** by enabling communication with non-sign-language users in real time.  

> **Programme:** PRJ381 â€“ Project 381  
> **Module Level:** NQF 8 (BCom â€“ Data Science/IT)  
> **Project Code:** AI-HG  
> **Academic Year:** 2025  

---

## ğŸ¯ Objectives  

- ğŸš€ Develop a **real-time hand gesture recognition** system.  
- ğŸ”Š Integrate **Text-to-Speech (TTS)** for gesture-to-speech conversion.  
- ğŸ§  Apply **deep learning techniques** to improve classification accuracy.  
- ğŸ‘¥ Test the application with real users for **usability and effectiveness**.  

---

## ğŸ› ï¸ Features  

- âœ… Real-time hand gesture detection (via **OpenCV + MediaPipe**)  
- âœ… Gesture classification using **CNN / transfer learning (TensorFlow / PyTorch)**  
- âœ… **Text-to-Speech integration** (gTTS, pyttsx3)  
- âœ… Python-based application with **GUI interface (Tkinter / Flask)**  
- âœ… Works across different **skin tones, hand sizes, and lighting conditions**  

---

## ğŸ“‚ Repository Structure  

```bash
PRJ381-Sim/
â”‚â”€â”€ data/                # Gesture datasets (raw & preprocessed)
â”‚â”€â”€ models/              # Trained CNN / transfer learning models
â”‚â”€â”€ notebooks/           # Jupyter/Colab notebooks for training & testing
â”‚â”€â”€ src/                 # Source code (Python scripts)
â”‚   â”œâ”€â”€ hand_tracking.py
â”‚   â”œâ”€â”€ gesture_classification.py
â”‚   â”œâ”€â”€ tts_integration.py
â”‚   â””â”€â”€ app.py           # Main application (GUI + real-time recognition)
â”‚â”€â”€ docs/                # Documentation, study guide & reports
â”‚â”€â”€ results/             # Test results, accuracy metrics, confusion matrices
â”‚â”€â”€ README.md            # Project overview (this file)
â”‚â”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ LICENSE              # License file
